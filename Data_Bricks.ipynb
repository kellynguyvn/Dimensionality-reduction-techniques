{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction using data bricks"
      ],
      "metadata": {
        "id": "J8Y8IYNLdpDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkJEI9uQazUq",
        "outputId": "f3dd6f6e-3f40-4b9a-b9af-9fdea0183bac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=fe9f230990cd378bc7ca188159fcfe534589d98c07ca71026a45886c8ae2fe32\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p99pDru4X048"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"dimensionalityReduction\").getOrCreate()"
      ],
      "metadata": {
        "id": "Atr98lVyakMh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "# Load the Iris dataset\n",
        "iris_df = spark.createDataFrame(datasets.load_iris().data.tolist(), [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])"
      ],
      "metadata": {
        "id": "Vowb4myNal2l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble features\n",
        "assembler = VectorAssembler(inputCols=iris_df.columns, outputCol=\"features\")\n",
        "iris_features = assembler.transform(iris_df)"
      ],
      "metadata": {
        "id": "6ZcLbCFZanKG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize PCA\n",
        "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pcaFeatures\")"
      ],
      "metadata": {
        "id": "Bed6cyC5aoxR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit PCA model\n",
        "model = pca.fit(iris_features)"
      ],
      "metadata": {
        "id": "ei--QXaHaqiQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data\n",
        "result = model.transform(iris_features).select(\"pcaFeatures\")\n"
      ],
      "metadata": {
        "id": "UGfELQBsasBM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the results\n",
        "result.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCRjhJATatTV",
        "outputId": "d88674a7-9c8c-4566-edba-e92d6256f353"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------+\n",
            "|pcaFeatures                              |\n",
            "+-----------------------------------------+\n",
            "|[-2.8182395066394674,-5.6463498234127965]|\n",
            "|[-2.788223445314678,-5.149951351762915]  |\n",
            "|[-2.613374563549707,-5.182003150742138]  |\n",
            "|[-2.757022276967594,-5.00865359757578]   |\n",
            "|[-2.7736485960544734,-5.653707089762616] |\n",
            "|[-3.221505499764511,-6.06828302589061]   |\n",
            "|[-2.681827381868395,-5.237491192299126]  |\n",
            "|[-2.8762201594623704,-5.490337536526024] |\n",
            "|[-2.6159824008284502,-4.748640822640992] |\n",
            "|[-2.8296093347880493,-5.213178330953578] |\n",
            "|[-2.9954180419571474,-5.97202147547627]  |\n",
            "|[-2.8896099017002808,-5.341682515989071] |\n",
            "|[-2.716255866420986,-5.091840576625977]  |\n",
            "|[-2.278561388743351,-4.815557989821313]  |\n",
            "|[-2.8576147426669736,-6.505717213265271] |\n",
            "|[-3.11632609907787,-6.665014907228348]   |\n",
            "|[-2.8788372573845766,-6.137632091008953] |\n",
            "|[-2.854068426354622,-5.63880172142105]   |\n",
            "|[-3.3025448089914233,-6.1997916157899065]|\n",
            "|[-2.914378732730235,-5.840512885576972]  |\n",
            "+-----------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "ERx9B2qjavCZ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}